{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb7ca02c-09b4-4227-9a35-fbd0b09ca9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 files\n"
     ]
    }
   ],
   "source": [
    "datadir = Path(\"/home/jdavidson/calms21/data\")\n",
    "base = \"/home/jdavidson/calms21/\"\n",
    "files = sorted(datadir.glob(\"*npy\"))\n",
    "print(f\"Found {len(files)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "114dce68-728e-4377-8cad-2a3be23db854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, re, json, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, average_precision_score, precision_recall_curve, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# I/O\n",
    "BASE = Path(base + \"socialmapper_outputs\")   # your features folder\n",
    "DATADIR = Path(datadir)                      # where .npy labels live\n",
    "\n",
    "# Task 3 label files (adjust names if yours differ)\n",
    "TASK3_TRAIN = DATADIR / \"calms21_task3_train.npy\"\n",
    "TASK3_TEST  = DATADIR / \"calms21_task3_test.npy\"\n",
    "\n",
    "# Behaviors to learn (7 new ones) \n",
    "TASK3_BEHAVIORS = ['approach', 'disengaged', 'groom', 'intromission', 'mount_attempt', 'sniff_face', 'whiterearing']\n",
    "\n",
    "# temporal-stack params (must match what you used to build X_train/X_test before)\n",
    "HALF = 50\n",
    "SKIP = 2\n",
    "ADD_POOL = True\n",
    "POOL_STATS = (\"mean\",\"std\")\n",
    "SIGMA_STACK = 25\n",
    "SIGMA_POOL  = 30\n",
    "\n",
    "# parallelism\n",
    "N_JOBS = 10\n",
    "\n",
    "# split\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# XGBoost (GPU if available)\n",
    "USE_GPU = True\n",
    "XGB_PARAMS = dict(\n",
    "    max_depth=8,\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=1500,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.0,\n",
    "    reg_lambda=1.0,\n",
    "    objective=\"binary:logistic\",\n",
    "    tree_method=(\"gpu_hist\" if USE_GPU else \"hist\"),\n",
    "    eval_metric=\"aucpr\",\n",
    "    n_jobs=0,\n",
    ")\n",
    "\n",
    "# ---- expected helpers from your current codebase ----\n",
    "# - to_raw_seq(safe_seq)\n",
    "# - load_gt_labels_from_many(...)  <-- we won't use; Task3 has its own label dicts\n",
    "# - _load_concat_wavelet(BASE, safe_seq, persp, allow_pair_only=False)\n",
    "# - temporal_stack_features(X, half_window, skip, add_pool, pool_stats, apply_to, sigma_stack, sigma_pool)\n",
    "# - sliding_stats_block (if you decide not to use temporal stacking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9981bfb4-6fd3-46e2-827b-c35cca8766af",
   "metadata": {},
   "source": [
    "# 2) Load Task-3 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e88fa9c5-f74c-488b-81e3-fc08ebd92f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_task3_dict(p: Path):\n",
    "    d = np.load(p, allow_pickle=True).item()\n",
    "    return d\n",
    "\n",
    "def load_task3_labels(train_path: Path, test_path: Path):\n",
    "    dtr = _load_task3_dict(train_path) if train_path.exists() else {}\n",
    "    dte = _load_task3_dict(test_path)  if test_path.exists()  else {}\n",
    "    return dtr, dte\n",
    "\n",
    "task3_train_dict, task3_test_dict = load_task3_labels(TASK3_TRAIN, TASK3_TEST)\n",
    "\n",
    "def has_any_labels_for_sequence_task3(dsplit: dict, raw_seq_key: str) -> bool:\n",
    "    for _, seqs in dsplit.items():\n",
    "        if raw_seq_key in seqs:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc0a3a0-1654-4e62-b15e-816b9546af7d",
   "metadata": {},
   "source": [
    "# 3) Discover sequences & build per-sequence features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a41bc38f-8454-4a4e-a439-8a7753cce498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34 TRAIN (seq,persp) with pair+ego.\n",
      "Found 218  TEST  (seq,persp) with pair+ego.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "BASE = Path(base + \"socialmapper_outputs\")  # adjust if needed\n",
    "\n",
    "# strict modern filenames only\n",
    "pat = re.compile(r\"wavelet_social_seq=(.*)_persp=(\\d+)\\.npz\")\n",
    "\n",
    "def _infer_split_from_safe(safe_seq: str) -> str:\n",
    "    # filenames look like: task3-<behavior>-train-... or task3-<behavior>-test-...\n",
    "    if \"-train-\" in safe_seq:\n",
    "        return \"train\"\n",
    "    if \"-test-\" in safe_seq:\n",
    "        return \"test\"\n",
    "    # fallback (shouldn't happen for Task 3)\n",
    "    return \"unknown\"\n",
    "\n",
    "def _list_index_for(pattern: str):\n",
    "    files = sorted(BASE.glob(pattern))\n",
    "    index = []\n",
    "    for p_pair in files:\n",
    "        m = pat.match(p_pair.name)\n",
    "        if not m:\n",
    "            continue\n",
    "        safe_seq, persp = m.group(1), int(m.group(2))\n",
    "        # require ego counterpart\n",
    "        p_ego = BASE / f\"wavelet_ego_seq={safe_seq}_persp={persp}.npz\"\n",
    "        if p_ego.exists():\n",
    "            split = _infer_split_from_safe(safe_seq)\n",
    "            index.append((safe_seq, persp, split))\n",
    "    return sorted(set(index))\n",
    "\n",
    "# enumerate train and test separately (you can also combine later if you want)\n",
    "index_train = _list_index_for(\"wavelet_social_seq=task3*train*persp=*.npz\")\n",
    "index_test  = _list_index_for(\"wavelet_social_seq=task3*test*persp=*.npz\")\n",
    "\n",
    "print(f\"Found {len(index_train)} TRAIN (seq,persp) with pair+ego.\")\n",
    "print(f\"Found {len(index_test)}  TEST  (seq,persp) with pair+ego.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a210afbe-eb56-48bf-80d5-eb584a699cb9",
   "metadata": {},
   "source": [
    "# 4) Build Task-3 dataset (temporal stack + labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b0f82f66-5e83-4b36-92f6-23580b962e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- strict helpers (modern names only) ----------\n",
    "\n",
    "def to_raw_seq(safe_seq: str) -> str:\n",
    "    \"\"\"CalMS21 key from 'safe' filename: replace '-' with '/'. \n",
    "       Example: task3-sniff_face-train-mouse023_task3_sniff_face -> task3/sniff_face/train/mouse023_task3_sniff_face\n",
    "    \"\"\"\n",
    "    return safe_seq.replace(\"-\", \"/\")\n",
    "\n",
    "def _ensure_TF(arr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Ensure (T,F): if rows<<cols it's likely (F,T) -> transpose.\"\"\"\n",
    "    if arr.ndim != 2:\n",
    "        raise ValueError(f\"Expected 2D array, got shape {arr.shape}\")\n",
    "    r, c = arr.shape\n",
    "    return arr.T if r <= c else arr\n",
    "\n",
    "def _find_pair_wavelet_file(in_dir: Path, safe_seq: str, persp: int) -> Path:\n",
    "    p = in_dir / f\"wavelet_social_seq={safe_seq}_persp={persp}.npz\"\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Missing pair wavelet: {p.name}\")\n",
    "    return p\n",
    "\n",
    "def _find_ego_wavelet_file(in_dir: Path, safe_seq: str, persp: int) -> Path:\n",
    "    p = in_dir / f\"wavelet_ego_seq={safe_seq}_persp={persp}.npz\"\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Missing ego wavelet: {p.name}\")\n",
    "    return p\n",
    "\n",
    "def _load_concat_wavelet(in_dir: Path, safe_seq: str, persp: int) -> np.ndarray:\n",
    "    \"\"\"Load pair + ego 'spectrogram' and hstack (truncate to min T). Returns float32 (T, F_pair+F_ego).\"\"\"\n",
    "    pair_path = _find_pair_wavelet_file(in_dir, safe_seq, persp)\n",
    "    ego_path  = _find_ego_wavelet_file(in_dir,  safe_seq, persp)\n",
    "    with np.load(pair_path) as P:\n",
    "        Xp = _ensure_TF(np.asarray(P[\"spectrogram\"]))\n",
    "    with np.load(ego_path) as E:\n",
    "        Xe = _ensure_TF(np.asarray(E[\"spectrogram\"]))\n",
    "    T = min(Xp.shape[0], Xe.shape[0])\n",
    "    return np.hstack([Xp[:T], Xe[:T]]).astype(np.float32, copy=False)\n",
    "\n",
    "# ---------- label dicts + robust accessor for Task 3 ----------\n",
    "\n",
    "def _load_task3_dict(p: Path) -> dict:\n",
    "    return np.load(p, allow_pickle=True).item()\n",
    "\n",
    "# point to your Task-3 npy files\n",
    "TASK3_TRAIN = Path(datadir) / \"calms21_task3_train.npy\"\n",
    "TASK3_TEST  = Path(datadir) / \"calms21_task3_test.npy\"\n",
    "\n",
    "task3_train_dict = _load_task3_dict(TASK3_TRAIN) if TASK3_TRAIN.exists() else {}\n",
    "task3_test_dict  = _load_task3_dict(TASK3_TEST)  if TASK3_TEST.exists()  else {}\n",
    "\n",
    "def _get_task3_seq_record(dsplit: dict, raw_seq_key: str):\n",
    "    \"\"\"Find the record payload for a sequence in a split dict.\"\"\"\n",
    "    for _, seqs in dsplit.items():\n",
    "        if raw_seq_key in seqs:\n",
    "            return seqs[raw_seq_key]\n",
    "    return None\n",
    "\n",
    "def get_task3_seq_labels(dsplit: dict, raw_seq_key: str, behavior: str) -> np.ndarray | None:\n",
    "    \"\"\"\n",
    "    Return (T,) 0/1 annotation vector for a given behavior and sequence.\n",
    "    Expects structure:\n",
    "        dsplit[behavior][raw_seq_key]['annotations'] -> array\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return np.asarray(dsplit[behavior][raw_seq_key][\"annotations\"]).astype(int)\n",
    "    except KeyError:\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] get_task3_seq_labels failed for {behavior} / {raw_seq_key}: {e}\")\n",
    "        return None\n",
    "\n",
    "# ---------- your temporal stacking (use the version you settled on) ----------\n",
    "\n",
    "\n",
    "def temporal_stack_features(\n",
    "    X: np.ndarray,\n",
    "    half_window: int = 16,\n",
    "    skip: int = 1,\n",
    "    add_pool: bool = True,\n",
    "    pool_stats=(\"mean\", \"std\"),\n",
    "    # --- Gaussian kernel controls ---\n",
    "    apply_to=(\"scale\", \"pool\"),     # any of {\"scale\", \"pool\"}; use () or None for none\n",
    "    sigma_stack: float = None,      # Gaussian sigma (frames) for the stacked (skip-sampled) offsets\n",
    "    sigma_pool: float = None        # Gaussian sigma (frames) for the dense pooling window\n",
    "):\n",
    "    \"\"\"\n",
    "    X: (T, F) per-frame features (e.g., wavelet over PCA for social pairs)\n",
    "    half_window: number of frames before/after the center\n",
    "    skip: take every 'skip' frame within the *stacked* window\n",
    "    add_pool: append pooled features over the full dense window\n",
    "    pool_stats: which pooled stats to append (\"mean\",\"std\",\"max\",\"min\")\n",
    "    apply_to: tuple indicating where to apply Gaussian weights:\n",
    "              - \"scale\": multiply stacked time slices by Gaussian weights before flattening\n",
    "              - \"pool\" : use Gaussian *weighted* pooling for mean/std (max/min remain unweighted)\n",
    "    sigma_stack: std dev (in frames) for the stacked offsets weighting\n",
    "    sigma_pool:  std dev (in frames) for the dense pooling weighting\n",
    "\n",
    "    Returns:\n",
    "      X_stack: (N_kept,  F*(num_steps)  [+ pooled dims])\n",
    "      keep_idx: (N_kept,) center indices in the original time axis\n",
    "    \"\"\"\n",
    "    if apply_to is None:\n",
    "        apply_to = tuple()\n",
    "    if isinstance(apply_to, str):\n",
    "        apply_to = (apply_to,)\n",
    "\n",
    "    T, F = X.shape\n",
    "\n",
    "    # --- Offsets for the *stacked* (skip-sampled) window ---\n",
    "    offsets = np.arange(-half_window, half_window + 1, skip, dtype=int)   # e.g., [-50,-45,...,0,...,45,50]\n",
    "    half_eff = offsets[-1]                                                # effective half-span considering skip\n",
    "\n",
    "    # centers we can keep without crossing sequence boundaries\n",
    "    start = max(half_window, half_eff)\n",
    "    end   = min(T - half_window, T - half_eff)\n",
    "    if end <= start:\n",
    "        return np.empty((0, F), dtype=X.dtype), np.array([], dtype=int)\n",
    "\n",
    "    centers = np.arange(start, end, dtype=int)           # center indices (N_kept,)\n",
    "    num_steps = len(offsets)\n",
    "\n",
    "    # --- Gaussian weights for the *stacked* offsets (for \"scale\") ---\n",
    "    if \"scale\" in apply_to:\n",
    "        w_stack = _gaussian_weights(offsets, sigma_stack)   # shape (num_steps,)\n",
    "    else:\n",
    "        w_stack = np.ones(num_steps, dtype=np.float32)\n",
    "\n",
    "    # --- Build stacked matrix, optionally Gaussian-scaled over time ---\n",
    "    X_stack = np.empty((len(centers), F * num_steps), dtype=X.dtype)\n",
    "    for i, t in enumerate(centers):\n",
    "        window = X[t + offsets, :]  # (num_steps, F)\n",
    "        if \"scale\" in apply_to:\n",
    "            window = (window * w_stack[:, None])            # apply temporal weights to each slice\n",
    "        X_stack[i] = window.reshape(-1)\n",
    "\n",
    "    # --- Optional pooled features over the *dense* window: [-half_window, +half_window] with step 1 ---\n",
    "    if add_pool:\n",
    "        dense_offsets = np.arange(-half_window, half_window + 1, dtype=int)  # every frame in the window\n",
    "        if \"pool\" in apply_to:\n",
    "            w_pool = _gaussian_weights(dense_offsets, sigma_pool)             # (2*half_window+1,)\n",
    "        else:\n",
    "            w_pool = None  # means \"flat\" pooling\n",
    "\n",
    "        pooled = []\n",
    "        for t in centers:\n",
    "            W = X[t - half_window : t + half_window + 1, :]  # (Twin_dense, F)\n",
    "            stats_parts = []\n",
    "            for stat in pool_stats:\n",
    "                if stat == \"mean\":\n",
    "                    if w_pool is None:\n",
    "                        stats_parts.append(W.mean(axis=0))\n",
    "                    else:\n",
    "                        stats_parts.append(_weighted_mean(W, w_pool))\n",
    "                elif stat == \"std\":\n",
    "                    if w_pool is None:\n",
    "                        stats_parts.append(W.std(axis=0))\n",
    "                    else:\n",
    "                        stats_parts.append(_weighted_std(W, w_pool))\n",
    "                elif stat == \"max\":\n",
    "                    stats_parts.append(W.max(axis=0))   # max/min are not naturally \"weighted\"\n",
    "                elif stat == \"min\":\n",
    "                    stats_parts.append(W.min(axis=0))\n",
    "            if stats_parts:\n",
    "                stats_vec = np.concatenate(stats_parts, axis=0)\n",
    "                pooled.append(stats_vec)\n",
    "\n",
    "        if pooled:  # if we actually added any stats\n",
    "            pooled = np.vstack(pooled)  # (N_kept, F * len(pool_stats))\n",
    "            X_stack = np.hstack([X_stack, pooled])\n",
    "\n",
    "    return X_stack, centers\n",
    "def align_labels(y, centers):\n",
    "    \"\"\"Pick the center-frame label for each stacked sample.\"\"\"\n",
    "    return y[centers]\n",
    "\n",
    "def align_labels(y: np.ndarray, centers: np.ndarray) -> np.ndarray:\n",
    "    return y[centers]\n",
    "\n",
    "# ---------- block builder that HONORS the split inferred from filename ----------\n",
    "\n",
    "def _infer_split_from_safe(safe_seq: str) -> str:\n",
    "    if \"-train-\" in safe_seq: return \"train\"\n",
    "    if \"-test-\"  in safe_seq: return \"test\"\n",
    "    return \"unknown\"\n",
    "\n",
    "def _one_block_task3(safe_seq: str, persp: int, behaviors: list[str]):\n",
    "    raw_seq = to_raw_seq(safe_seq)\n",
    "    split = _infer_split_from_safe(safe_seq)\n",
    "    dsplit = task3_train_dict if split == \"train\" else task3_test_dict if split == \"test\" else None\n",
    "    if dsplit is None:\n",
    "        return None\n",
    "\n",
    "    # if sequence is absent from that split's labels, skip early\n",
    "    if _get_task3_seq_record(dsplit, raw_seq) is None:\n",
    "        return None\n",
    "\n",
    "    # features\n",
    "    X = _load_concat_wavelet(BASE, safe_seq, persp)  # (T, F_pair+F_ego)\n",
    "\n",
    "    # temporal stack\n",
    "    Xw, centers = temporal_stack_features(\n",
    "        X, half_window=HALF, skip=SKIP, add_pool=ADD_POOL, pool_stats=POOL_STATS,\n",
    "        apply_to=(\"scale\", \"pool\"), sigma_stack=SIGMA_STACK, sigma_pool=SIGMA_POOL\n",
    "    )\n",
    "    if Xw.shape[0] == 0:\n",
    "        return None\n",
    "\n",
    "    # per-behavior labels (from the *correct* split dict)\n",
    "    y_per_b = {}\n",
    "    T = X.shape[0]\n",
    "    for b in behaviors:\n",
    "        y_seq = get_task3_seq_labels(dsplit, raw_seq, b)\n",
    "        if y_seq is None:\n",
    "            continue\n",
    "        n = min(T, y_seq.shape[0])\n",
    "        y_per_b[b] = y_seq[:n][centers].astype(int)\n",
    "\n",
    "    if not y_per_b:\n",
    "        return None\n",
    "\n",
    "    g_block = np.full(Xw.shape[0], raw_seq, dtype=object)\n",
    "    return dict(X=Xw, y_per_b=y_per_b, g=g_block, seq=raw_seq, persp=persp, split=split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ed5df9e2-2c02-4ac8-a98a-c3e32ca395ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Task3 TRAIN: load+stack:   0%|                                                                          | 0/34 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Task3 TRAIN: load+stack:  59%|██████████████████████████████████████▏                          | 20/34 [00:01<00:01, 12.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Task3 TRAIN: load+stack: 100%|█████████████████████████████████████████████████████████████████| 34/34 [00:09<00:00,  3.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task3 TRAIN blocks: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Task3 TEST: load+stack:   0%|                                                                          | 0/218 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Task3 TEST: load+stack:   9%|█████▉                                                           | 20/218 [00:01<00:15, 12.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A/home/jdavidson/miniforge3/envs/ecodylic/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Task3 TEST: load+stack:  14%|████████▉                                                        | 30/218 [00:07<00:52,  3.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Task3 TEST: load+stack:  18%|███████████▉                                                     | 40/218 [00:11<00:59,  3.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Task3 TEST: load+stack:  23%|██████████████▉                                                  | 50/218 [00:14<00:55,  3.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Task3 TEST: load+stack:  28%|█████████████████▉                                               | 60/218 [00:17<00:48,  3.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Task3 TEST: load+stack:  32%|████████████████████▊                                            | 70/218 [00:20<00:48,  3.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Task3 TEST: load+stack:  37%|███████████████████████▊                                         | 80/218 [00:30<01:11,  1.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Task3 TEST: load+stack:  41%|██████████████████████████▊                                      | 90/218 [00:36<01:12,  1.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Task3 TEST: load+stack:  46%|█████████████████████████████▎                                  | 100/218 [00:41<01:03,  1.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Task3 TEST: load+stack:  50%|████████████████████████████████▎                               | 110/218 [00:44<00:49,  2.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Task3 TEST: load+stack:  55%|███████████████████████████████████▏                            | 120/218 [00:50<00:48,  2.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Task3 TEST: load+stack:  60%|██████████████████████████████████████▏                         | 130/218 [00:54<00:42,  2.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Task3 TEST: load+stack:  64%|█████████████████████████████████████████                       | 140/218 [00:58<00:35,  2.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Task3 TEST: load+stack:  69%|████████████████████████████████████████████                    | 150/218 [01:03<00:32,  2.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Task3 TEST: load+stack:  73%|██████████████████████████████████████████████▉                 | 160/218 [01:09<00:28,  2.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Task3 TEST: load+stack:  78%|█████████████████████████████████████████████████▉              | 170/218 [01:12<00:21,  2.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Task3 TEST: load+stack:  83%|████████████████████████████████████████████████████▊           | 180/218 [01:17<00:17,  2.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Task3 TEST: load+stack:  87%|███████████████████████████████████████████████████████▊        | 190/218 [01:20<00:11,  2.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Task3 TEST: load+stack:  92%|██████████████████████████████████████████████████████████▋     | 200/218 [01:23<00:06,  2.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Task3 TEST: load+stack: 100%|████████████████████████████████████████████████████████████████| 218/218 [01:26<00:00,  2.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task3 TEST blocks: 218\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Build TRAIN blocks\n",
    "blocks_train = Parallel(n_jobs=N_JOBS, prefer=\"processes\")(\n",
    "    delayed(_one_block_task3)(safe_seq, persp, TASK3_BEHAVIORS)\n",
    "    for (safe_seq, persp, split) in tqdm(index_train, desc=\"Task3 TRAIN: load+stack\")\n",
    ")\n",
    "blocks_train = [b for b in blocks_train if b is not None]\n",
    "print(f\"Task3 TRAIN blocks: {len(blocks_train)}\")\n",
    "\n",
    "# Build TEST blocks\n",
    "blocks_test = Parallel(n_jobs=N_JOBS, prefer=\"processes\")(\n",
    "    delayed(_one_block_task3)(safe_seq, persp, TASK3_BEHAVIORS)\n",
    "    for (safe_seq, persp, split) in tqdm(index_test, desc=\"Task3 TEST: load+stack\")\n",
    ")\n",
    "blocks_test = [b for b in blocks_test if b is not None]\n",
    "print(f\"Task3 TEST blocks: {len(blocks_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6442a92a-2dd4-4e7e-bcae-ea778a7c25bb",
   "metadata": {},
   "source": [
    "# 5 assemble per-behavior datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c5c3267d-a28c-410c-a4d0-1d98ac511199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def _concat_blocks_for_behavior(blocks, behavior: str):\n",
    "    Xs, ys, gs = [], [], []\n",
    "    for b in blocks:\n",
    "        if behavior in b[\"y_per_b\"]:\n",
    "            Xs.append(b[\"X\"])\n",
    "            ys.append(b[\"y_per_b\"][behavior])\n",
    "            gs.append(b[\"g\"])\n",
    "    if not Xs:\n",
    "        return None, None, None\n",
    "    return (np.vstack(Xs).astype(np.float32, copy=False),\n",
    "            np.concatenate(ys).astype(np.int32, copy=False),\n",
    "            np.concatenate(gs))\n",
    "\n",
    "# example usage later:\n",
    "# Xtr_b, ytr_b, gtr_b = _concat_blocks_for_behavior(blocks_train, \"sniff_face\")\n",
    "# Xte_b, yte_b, gte_b = _concat_blocks_for_behavior(blocks_test,  \"sniff_face\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b84525b-ac08-4bc6-b287-b4e5e10ff9a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba03c5f4-ef2a-4556-b30e-020b31d305d9",
   "metadata": {},
   "source": [
    "# 6  train XGBoost per behavior (with class-imbalance handling + val split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2ba1568c-f16a-47b7-9d67-df8fe2345b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import average_precision_score, f1_score, precision_recall_curve\n",
    "import xgboost as xgb\n",
    "from pathlib import Path\n",
    "import json, os\n",
    "\n",
    "OUT_DIR = (BASE / \"task3_xgb_models\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _train_val_split(X, y, test_size=0.2, random_state=42):\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "    (tr_idx, va_idx), = sss.split(X, y)\n",
    "    return X[tr_idx], y[tr_idx], X[va_idx], y[va_idx]\n",
    "\n",
    "def _scale_pos_weight(y):\n",
    "    # (neg / pos) — guard rare class\n",
    "    pos = np.count_nonzero(y == 1)\n",
    "    neg = y.size - pos\n",
    "    return float(neg / max(1, pos))\n",
    "\n",
    "def train_xgb_for_behavior(behavior: str, Xtr, ytr, Xte, yte, *,\n",
    "                           use_gpu=True, random_state=42):\n",
    "    # split TRAIN into (train, val) for early stopping + threshold tuning\n",
    "    X_tr, y_tr, X_va, y_va = _train_val_split(Xtr, ytr, test_size=0.2, random_state=random_state)\n",
    "\n",
    "    params = dict(\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"aucpr\",\n",
    "        tree_method=\"hist\",\n",
    "        device=\"cuda\", # GPU acceleration\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.7,\n",
    "        reg_lambda=1.0,\n",
    "        reg_alpha=0.0,\n",
    "        random_state=random_state,\n",
    "        scale_pos_weight=_scale_pos_weight(y_tr),\n",
    "        n_estimators=4000,  # we will early-stop\n",
    "    )\n",
    "\n",
    "    clf = xgb.XGBClassifier(**params)\n",
    "    clf.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_va, y_va)],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # threshold tuning on **validation** (maximize F1 or Youden’s J on PR curve)\n",
    "    va_proba = clf.predict_proba(X_va)[:, 1]\n",
    "    precision, recall, thresh = precision_recall_curve(y_va, va_proba)\n",
    "    f1s = np.where((precision + recall) > 0, 2 * precision * recall / (precision + recall), 0.0)\n",
    "    best_i = int(np.nanargmax(f1s))\n",
    "    best_thr = float(thresh[max(0, best_i - 1)]) if best_i > 0 else 0.5  # PR returns len(thresh)=len(precision)-1\n",
    "\n",
    "    # test evaluation\n",
    "    te_proba = clf.predict_proba(Xte)[:, 1]\n",
    "    y_pred = (te_proba >= best_thr).astype(np.int32)\n",
    "    ap = average_precision_score(yte, te_proba)\n",
    "    f1 = f1_score(yte, y_pred, zero_division=0)\n",
    "\n",
    "    # save\n",
    "    beh_dir = OUT_DIR / behavior\n",
    "    beh_dir.mkdir(exist_ok=True, parents=True)\n",
    "    model_path = beh_dir / \"xgb.json\"\n",
    "    clf.get_booster().save_model(model_path.as_posix())\n",
    "    with open(beh_dir / \"metrics.json\", \"w\") as f:\n",
    "        json.dump({\n",
    "            \"behavior\": behavior,\n",
    "            \"best_iteration\": int(clf.best_iteration) if hasattr(clf, \"best_iteration\") else None,\n",
    "            \"val_best_threshold\": best_thr,\n",
    "            \"test_AP\": ap,\n",
    "            \"test_F1\": f1,\n",
    "            \"class_counts_train\": {\n",
    "                \"pos\": int(np.sum(y_tr==1)),\n",
    "                \"neg\": int(np.sum(y_tr==0)),\n",
    "                \"scale_pos_weight\": params[\"scale_pos_weight\"],\n",
    "            }\n",
    "        }, f, indent=2)\n",
    "\n",
    "    return dict(model=clf, thr=best_thr, AP=ap, F1=f1, path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57c1d7d-8e86-4088-8ade-4bc4672f1c50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9aeb07b3-dd03-4df0-bb62-a68754d36134",
   "metadata": {},
   "source": [
    "# 7 run the loop over all Task-3 behaviors and report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a642e3-75f0-47a3-90b9-4361d562f856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training XGB for approach ===\n",
      "  train: X=(40648, 4770), pos=1328, neg=39320\n",
      "  test : X=(247936, 4770), pos=7572, neg=240364\n",
      "--- approach test report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.971     0.990     0.980    240364\n",
      "           1      0.149     0.058     0.083      7572\n",
      "\n",
      "    accuracy                          0.961    247936\n",
      "   macro avg      0.560     0.524     0.532    247936\n",
      "weighted avg      0.946     0.961     0.953    247936\n",
      "\n",
      "Confusion matrix:\n",
      " [[237864   2500]\n",
      " [  7134    438]]\n",
      "AP=0.0723  F1=0.0833  thr=0.024  -> xgb.json\n",
      "\n",
      "=== Training XGB for disengaged ===\n",
      "  train: X=(71102, 4770), pos=1048, neg=70054\n",
      "  test : X=(37976, 4770), pos=456, neg=37520\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "results_task3 = {}\n",
    "\n",
    "for behavior in TASK3_BEHAVIORS:\n",
    "    Xtr_b, ytr_b, _ = _concat_blocks_for_behavior(blocks_train, behavior)\n",
    "    Xte_b, yte_b, _ = _concat_blocks_for_behavior(blocks_test,  behavior)\n",
    "\n",
    "    if Xtr_b is None or Xte_b is None:\n",
    "        print(f\"[WARN] {behavior}: missing data; skipping.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n=== Training XGB for {behavior} ===\")\n",
    "    print(f\"  train: X={Xtr_b.shape}, pos={np.sum(ytr_b==1)}, neg={np.sum(ytr_b==0)}\")\n",
    "    print(f\"  test : X={Xte_b.shape}, pos={np.sum(yte_b==1)}, neg={np.sum(yte_b==0)}\")\n",
    "\n",
    "    out = train_xgb_for_behavior(behavior, Xtr_b, ytr_b, Xte_b, yte_b, use_gpu=True)\n",
    "\n",
    "    # detailed test report (at tuned threshold)\n",
    "    yhat = (out[\"model\"].predict_proba(Xte_b)[:,1] >= out[\"thr\"]).astype(np.int32)\n",
    "    print(f\"--- {behavior} test report ---\")\n",
    "    print(classification_report(yte_b, yhat, digits=3, zero_division=0))\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(yte_b, yhat))\n",
    "    print(f\"AP={out['AP']:.4f}  F1={out['F1']:.4f}  thr={out['thr']:.3f}  -> {out['path'].name}\")\n",
    "\n",
    "    results_task3[behavior] = dict(AP=out[\"AP\"], F1=out[\"F1\"], thr=out[\"thr\"])\n",
    "\n",
    "# quick summary\n",
    "print(\"\\n=== Task 3 summary (TEST) ===\")\n",
    "for b, r in results_task3.items():\n",
    "    print(f\"{b:15s}  AP={r['AP']:.4f}  F1={r['F1']:.4f}  thr={r['thr']:.3f}\")\n",
    "print(\"Macro averages:\",\n",
    "      \"AP=\", np.mean([r[\"AP\"] for r in results_task3.values()]).round(4),\n",
    "      \"F1=\", np.mean([r[\"F1\"] for r in results_task3.values()]).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6d8471-ec8d-43eb-8eef-c7d1bba3f077",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

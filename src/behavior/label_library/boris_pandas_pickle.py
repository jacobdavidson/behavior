"""
BORIS Pandas DataFrame pickle label converter.

BORIS (Behavioral Observation Research Interactive Software) can export
behavioral observations as a Pandas DataFrame saved with pickle. This format
preserves all data types and structure from the aggregated events export.

The pickle format contains the same data as the aggregated CSV/TSV export,
but with proper Python data types (datetime, float, etc.) already applied.

Expected structure:
    DataFrame with columns including:
    - Observation id (str)
    - Observation date (datetime or str)
    - Description (str)
    - Media file (str)
    - Total length (float)
    - FPS (float)
    - Subject (str)
    - Behavior (str)
    - Behavioral category (str)
    - Modifiers (empty if none) (str)
    - Behavior type (str): "STATE" or "POINT"
    - Start (s) (float)
    - Stop (s) (float)
    - Duration (s) (float or NaN for point events)
    - Comment start (str)
    - Comment stop (str)
    - [Independent variables columns]

Loading:
    import pandas as pd
    df = pd.read_pickle('boris_export.pkl')

References
----------
BORIS User Guide: http://www.boris.unito.it/user_guide/export_events/
GitHub: https://github.com/olivierfriard/BORIS
"""

from pathlib import Path
from typing import Optional, Dict, Any, Tuple
import pandas as pd
import numpy as np

from behavior.helpers import to_safe_name


def _merge_params(overrides: Optional[Dict[str, Any]], defaults: Dict[str, Any]) -> Dict[str, Any]:
    """Helper to merge user params with defaults."""
    if not overrides:
        return dict(defaults)
    out = dict(defaults)
    out.update({k: v for k, v in overrides.items() if v is not None})
    return out


class BorisPandasPickleConverter:
    """
    Convert BORIS Pandas DataFrame pickle to behavior dataset format.

    This converter processes BORIS pickle exports created with:
        df.to_pickle('filename.pkl')

    The pickle format contains the same aggregated event data as CSV/TSV
    exports but with preserved data types (datetime, float, etc.).

    The converter:
    1. Loads the Pandas DataFrame from pickle
    2. Auto-detects FPS from the DataFrame or uses provided parameter
    3. Groups events by observation and subject
    4. Converts time-based events to frame-by-frame labels
    5. Creates one sequence per (observation, subject) combination

    Usage
    -----
    >>> dataset.convert_all_labels(
    ...     kind="behavior",
    ...     source_format="boris_pandas_pickle",
    ...     group_from="filename",
    ...     fps=None,  # Auto-detect from DataFrame
    ... )

    Parameters
    ----------
    group_from : str, default="filename"
        How to determine group name
    fps : float or None, default=None
        Frames per second. If None, auto-detected from FPS column in DataFrame
    background_label : str, default="none"
        Label to use when no behavior is active
    no_focal_subject_name : str, default="no_focal_subject"
        Name to use for behaviors with "No focal subject"
    include_point_events : bool, default=True
        Whether to include POINT events (instantaneous behaviors)
    observation_col : str, default="Observation id"
        Column name for observation identifier
    subject_col : str, default="Subject"
        Column name for subject
    behavior_col : str, default="Behavior"
        Column name for behavior
    start_col : str, default="Start (s)"
        Column name for start time
    stop_col : str, default="Stop (s)"
        Column name for stop time
    behavior_type_col : str, default="Behavior type"
        Column name for behavior type (STATE/POINT)
    fps_col : str, default="FPS"
        Column name for FPS value
    """

    # ============ REGISTRATION ATTRIBUTES ============
    src_format = "boris_pandas_pickle"
    label_kind = "behavior"
    label_format = "boris_pandas_v1"

    # ============ DEFAULT PARAMETERS ============
    _defaults = dict(
        group_from="filename",
        fps=None,  # Auto-detect from DataFrame
        background_label="none",
        no_focal_subject_name="no_focal_subject",
        include_point_events=True,
        # Column names (can be overridden if BORIS export format changes)
        observation_col="Observation id",
        subject_col="Subject",
        behavior_col="Behavior",
        start_col="Start (s)",
        stop_col="Stop (s)",
        behavior_type_col="Behavior type",
        fps_col="FPS",
        category_col="Behavioral category",
        modifiers_col="Modifiers (empty if none)",
    )

    def __init__(self, params: Optional[Dict[str, Any]] = None, **kwargs):
        """Initialize the converter with parameters."""
        self.params = _merge_params(params, self._defaults)
        self.params.update(kwargs)

    def convert(self,
                src_path: Path,
                raw_row: pd.Series,
                labels_root: Path,
                params: dict,
                overwrite: bool,
                existing_pairs: set[tuple[str, str]]) -> list[dict]:
        """
        Convert BORIS Pandas pickle to per-sequence behavior labels.

        Parameters
        ----------
        src_path : Path
            Path to BORIS pickle file (.pkl)
        raw_row : pd.Series
            Row from tracks_raw/index.csv
        labels_root : Path
            Output directory for label files
        params : dict
            Conversion parameters
        overwrite : bool
            Whether to overwrite existing files
        existing_pairs : set[tuple[str, str]]
            Already converted (group, sequence) pairs

        Returns
        -------
        list[dict]
            Index rows for labels/index.csv
        """
        p = self.params

        # Load BORIS DataFrame from pickle
        try:
            df = pd.read_pickle(src_path)
        except Exception as e:
            raise ValueError(f"Failed to load BORIS pickle file: {e}")

        if not isinstance(df, pd.DataFrame):
            raise ValueError(
                f"Expected DataFrame in pickle file, got {type(df)}. "
                f"File may not be a BORIS export."
            )

        # Validate required columns
        required_cols = [
            p["observation_col"],
            p["subject_col"],
            p["behavior_col"],
            p["start_col"],
            p["stop_col"],
        ]
        missing = [c for c in required_cols if c not in df.columns]
        if missing:
            raise ValueError(
                f"BORIS DataFrame missing required columns: {missing}\n"
                f"Available columns: {list(df.columns)}"
            )

        # Auto-detect FPS if not provided
        fps = p["fps"]
        if fps is None:
            if p["fps_col"] in df.columns:
                fps_values = df[p["fps_col"]].dropna().unique()
                if len(fps_values) == 0:
                    raise ValueError("FPS column exists but contains no valid values")
                elif len(fps_values) > 1:
                    print(f"Warning: Multiple FPS values found: {fps_values}. Using first: {fps_values[0]}")
                fps = float(fps_values[0])
            else:
                raise ValueError(
                    f"FPS not provided and '{p['fps_col']}' column not found in DataFrame. "
                    f"Please specify fps parameter."
                )

        print(f"Using FPS: {fps}")

        # Build label map from unique behaviors
        unique_behaviors = sorted(df[p["behavior_col"]].dropna().unique())
        if p["background_label"] not in unique_behaviors:
            unique_behaviors = [p["background_label"]] + unique_behaviors

        label_map = {i: name for i, name in enumerate(unique_behaviors)}
        label_name_to_id = {name: i for i, name in label_map.items()}

        # Determine group name
        group_val = self._determine_group("", raw_row)

        # Group by observation and subject
        obs_col = p["observation_col"]
        subj_col = p["subject_col"]

        # Handle NaN in subject column (treat as no focal subject)
        df[subj_col] = df[subj_col].fillna(p["no_focal_subject_name"])

        rows_out = []

        # Process each (observation, subject) combination as a sequence
        for (obs_id, subject), obs_subj_df in df.groupby([obs_col, subj_col]):
            # Create sequence identifier
            # Format: observation_id__subject_name
            obs_safe = to_safe_name(str(obs_id))
            subj_safe = to_safe_name(str(subject))
            seq_val = f"{obs_safe}__{subj_safe}"

            pair = (group_val, seq_val)

            # Skip if exists
            if not overwrite and pair in existing_pairs:
                continue

            # Convert events to frame-by-frame labels
            labels, frames = self._convert_to_frame_labels(
                obs_subj_df, label_name_to_id, fps, p
            )

            # Create safe names and output path
            safe_group = to_safe_name(group_val) if group_val else ""
            safe_seq = to_safe_name(seq_val)
            fname = f"{safe_group + '__' if safe_group else ''}{safe_seq}.npz"
            out_path = labels_root / fname

            # Build npz payload
            label_ids = np.array(list(label_map.keys()), dtype=int)
            label_names = np.array(list(label_map.values()), dtype=object)

            payload = {
                "group": group_val,
                "sequence": seq_val,
                "sequence_key": seq_val,
                "frames": frames,
                "labels": labels,
                "label_ids": label_ids,
                "label_names": label_names,
                "source_observation": str(obs_id),
                "source_subject": str(subject),
                "fps": float(fps),
            }

            # Save npz
            np.savez_compressed(out_path, **payload)
            existing_pairs.add(pair)

            # Build index row
            index_row = {
                "kind": self.label_kind,
                "label_format": self.label_format,
                "group": group_val,
                "sequence": seq_val,
                "group_safe": safe_group,
                "sequence_safe": safe_seq,
                "abs_path": str(out_path.resolve()),
                "source_abs_path": str(src_path.resolve()),
                "source_md5": raw_row.get("md5", ""),
                "n_frames": int(labels.shape[0]),
                "label_ids": ",".join(map(str, label_map.keys())),
                "label_names": ",".join(label_map.values()),
                "source_observation": str(obs_id),
                "source_subject": str(subject),
                "fps": str(fps),
            }
            rows_out.append(index_row)

        return rows_out

    def get_metadata(self) -> dict:
        """Return metadata for dataset.meta."""
        return {
            "fps": self.params.get("fps"),
            "source_format": "BORIS Pandas Pickle",
        }

    # ============ HELPER METHODS ============

    def _determine_group(self, source_group: str, raw_row: pd.Series) -> str:
        """Determine output group name based on group_from parameter."""
        group_from = self.params.get("group_from", "filename")
        if group_from == "filename":
            return str(raw_row.get("group", "") or "")
        elif group_from == "infile":
            return source_group
        elif group_from == "both":
            return str(raw_row.get("group", "") or "")
        else:
            return source_group

    def _convert_to_frame_labels(self,
                                 df: pd.DataFrame,
                                 label_map: dict,
                                 fps: float,
                                 params: dict) -> Tuple[np.ndarray, np.ndarray]:
        """
        Convert BORIS event table to frame-by-frame labels.

        Parameters
        ----------
        df : pd.DataFrame
            Events for a single (observation, subject) pair
        label_map : dict
            Behavior name to ID mapping
        fps : float
            Frames per second
        params : dict
            Converter parameters

        Returns
        -------
        labels : np.ndarray
            Per-frame behavior labels, shape (n_frames,)
        frames : np.ndarray
            Frame indices, shape (n_frames,)
        """
        behavior_col = params["behavior_col"]
        start_col = params["start_col"]
        stop_col = params["stop_col"]
        behavior_type_col = params["behavior_type_col"]
        background_id = label_map[params["background_label"]]
        include_point = params["include_point_events"]

        # Determine total duration (last stop time)
        max_time = df[stop_col].max()
        n_frames = int(np.ceil(max_time * fps)) + 1

        # Initialize with background label
        labels = np.full(n_frames, background_id, dtype=int)

        # Process each event
        for _, row in df.iterrows():
            behavior = row[behavior_col]
            behavior_id = label_map.get(behavior, background_id)

            start_time = row[start_col]
            stop_time = row[stop_col]

            # Convert times to frames
            start_frame = int(start_time * fps)
            stop_frame = int(stop_time * fps)

            # Check if this is a point event
            if behavior_type_col in df.columns:
                behavior_type = str(row[behavior_type_col]).upper()
                is_point = behavior_type == "POINT"
            else:
                # If no behavior type column, infer from start == stop
                is_point = abs(start_time - stop_time) < 1e-6

            if is_point:
                if include_point:
                    # Mark only the single frame
                    if 0 <= start_frame < n_frames:
                        labels[start_frame] = behavior_id
            else:
                # State event: fill all frames in range
                start_frame = max(0, start_frame)
                stop_frame = min(n_frames - 1, stop_frame)
                labels[start_frame:stop_frame + 1] = behavior_id

        frames = np.arange(n_frames, dtype=np.int32)
        return labels, frames
